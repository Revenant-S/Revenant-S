---
title: Python爬虫报错合集
date: 2021-08-04 16:24:26
categories:
- 2021-08
tags:
- Python
---

<center>Python爬虫报错合集</center>

<!-- more -->

# 在爬取时出现这种错误

```sh
ConnectionError: HTTPConnectionPool(host='xxx.xx.xxx.xxx', port=xxxx): Max retries exceeded with url
```

原因及解决方案如下：

1. http连接太多没有关闭导致的，解决方法：

```python
import requests
requests.adapters.DEFAULT_RETRIES = 5 # 增加重连次数
s = requests.session()
s.keep_alive = False # 关闭多余连接
s.get(url) # 你需要的网址
```

2. 访问次数频繁，被禁止访问，解决方法：使用代理

```python
import requests
s = requests.session()
url = ""
s.proxies = {"https": "47.100.104.247:8080", }
s.headers = headers
s.get(url)
```

